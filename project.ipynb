{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDS Mini Project\n",
    "\n",
    "\n",
    "**WARNING: Before making any git commit to this notebook please clear all output in this notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning the data\n",
    "\n",
    "### Invalid Columns: \n",
    "- delete unnamed column which was serving as index (index already exists - duplicated column)\n",
    "- delete last column (contains only NaN values) - 'Unnamed 21'\n",
    "\n",
    "### NaN values:\n",
    "- check number of NaN values/location of NaN values\n",
    "- leave NaN values that are required in order not to lose data (for example: a cancelled flight will always have NaN values for DEP_TIME, ARR_TIME, ARR_DEL15, DEP_DEL15 - as the flight did not happen)\n",
    "- delete NaN values that would incommodate analysis and plotting later on (for example, flight timings that are simply missing without the flight having been cancelled)\n",
    "\n",
    "### Times conversion (Note: 00:00 timings all represent cancelled flights)\n",
    "- observation --> no flight leaves at 00:00, all *00:00 date/time values belong to flights that have been cancelled*\n",
    "- converted DEP_TIME and ARR_TIME to 4-character string of the format: hhmm (error when attempting to convert to date/time) \n",
    "- added two extra columns: ARR_TIME_MINS and DEP_TIME_MINS representing the arrival and departure time in minutes for easier calculations\n",
    "\n",
    "### Irrelevant columns (to this project) to be removed/ duplicated data:\n",
    "- Remove both OP_CARRIER_AIRLINE_ID and OP_CARRIER\n",
    "- Remove ORIGIN_AIRPORT_SEQ_ID\n",
    "- Remove DEST_AIRPORT_SEQ_ID\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Importing sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------- Load dataset ------------------------------------------#\n",
    "flight_data_path = os.path.join(os.getcwd(), 'datasets', 'flight_jan_2019.csv.gz')\n",
    "flight_data = pd.read_csv(flight_data_path, compression = 'gzip')\n",
    "\n",
    "# Delete 'Unnamed 1' and 'Unnamed 21'\n",
    "del flight_data['Unnamed: 0']\n",
    "del flight_data['Unnamed: 21']\n",
    "flight_data\n",
    "\n",
    "#---------------------------------------- Check for 'NaN' values ------------------------------#\n",
    "\n",
    "# for col in flight_data.columns: \n",
    "#    print(col, ' :',flight_data[col].isna().sum())\n",
    "    \n",
    "    # NA VALUES: TAIL_NUM  : 2543\n",
    "    #            DEP_TIME  : 16352\n",
    "    #            DEP_DEL15  : 16355\n",
    "    #            ARR_TIME  : 17061\n",
    "    #            ARR_DEL15  : 18022\n",
    "    #            Unnamed: 21  : 583985\n",
    "\n",
    "# Dealing with DEP_TIME and ARR_TIME Nan values\n",
    "flight_data[np.isnan(flight_data.DEP_TIME)] # Observation: cancelled flights have Nan values for DEP_TIME, ARR_TIME, DEP_DEL15,ARR_DEL15  \n",
    "# NaN values therefore make sense in this case, eliminating rows with NaN values with plotting can be done by filtering:\n",
    "#                       flight_data[~np.isnan(flight_data['DEP_TIME'])]['DEP_TIME'].isna().sum()    \n",
    "\n",
    "# Eliminate rows with NaN values in place for DEP/ARR_DELL15 AND ARR_TIME where the DEP_TIME is registered (timings simply missing)\n",
    "indices_to_eliminate = list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['DEP_DEL15'])].index.values) + list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['ARR_TIME'])].index.values) + list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['ARR_DEL15'])].index.values)\n",
    "flight_data = flight_data.drop(indices_to_eliminate)\n",
    "\n",
    "#--------------------------------------Modifying data types----------------------------------#\n",
    "flight_data.dtypes\n",
    "# CANCELLED/DIVERTED to integer value\n",
    "flight_data['CANCELLED'] = flight_data['CANCELLED'].astype(int)\n",
    "flight_data['DIVERTED'] = flight_data['DIVERTED'].astype(int)\n",
    "flight_data.dtypes\n",
    "flight_data\n",
    "# Modifying timings date/time format\n",
    "#flight_data['DEP_TIME'] = pd.to_datetime(flight_data['DEP_TIME'], format='%H%M').dt.time\n",
    "\n",
    "# OBSERVATION: flights with value 0.0 - keeping in mind that timings are currently floats - are all NaN values - so no flight leaves at 00:00 (those are simply cancelled values)\n",
    "len(flight_data[(flight_data['DEP_TIME'] == 0.0)][flight_data['CANCELLED'] == 1]['DEP_TIME']) - flight_data[flight_data['DEP_TIME'] == 0.0]['DEP_TIME'].isna().sum()\n",
    "len(flight_data[(flight_data['DEP_TIME'] == 0.0)][flight_data['CANCELLED'] == 1]['DEP_TIME']) - flight_data[flight_data['DEP_TIME'] == 0.0]['DEP_TIME'].isna().sum()\n",
    "\n",
    "# Convert DEP_TIME and ARR_TIME to int and add new columns: DEP_TIME_MINS and ARR_TIME_MINS for easy calculations\n",
    "def convert_minutes(x):\n",
    "    minutes = int(x[2])*10 + int(x[3])\n",
    "    hr_minutes = (int(x[0])*10 + int(x[1]))*60\n",
    "    return minutes+hr_minutes\n",
    "\n",
    "def fill_in(x):\n",
    "    if (len(x) == 4):\n",
    "        return x\n",
    "    if (len(x) == 3):\n",
    "        return '0' + x\n",
    "    if (len(x) == 2):\n",
    "        return '00' + x\n",
    "    if (len(x) == 1):\n",
    "        return '000' + x\n",
    "    if (len(x) == 0):\n",
    "        return '000' + x\n",
    "    return '0000'\n",
    "    \n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].fillna(0)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].astype(int)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].astype(str)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(fill_in)\n",
    "flight_data['DEP_TIME_MINS'] = flight_data['DEP_TIME'].apply(convert_minutes)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].fillna(0)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].astype(int)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].astype(str)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].apply(fill_in)\n",
    "flight_data['ARR_TIME_MINS'] = flight_data['ARR_TIME'].apply(convert_minutes)\n",
    "\n",
    "#-------------------------------ATTEMPT AT CONVERTING TO DATE/TIME-----------------#\n",
    "def fill_in(x):\n",
    "    if (len(x) == 4):\n",
    "        return x\n",
    "    if (len(x) == 3):\n",
    "        return '0' + x\n",
    "    if (len(x) == 2):\n",
    "        return '00' + x\n",
    "    if (len(x) == 1):\n",
    "        return '000' + x\n",
    "    if (len(x) == 0):\n",
    "        return '000' + x\n",
    "    return '0000'\n",
    "    \n",
    "#def convert_time(x):\n",
    "#    return datetime.datetime.strptime(x,'%H%M' )\n",
    "    \n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(fill_in)\n",
    "#flight_data['ARR_TIME'] = flight_data['ARR_TIME'].apply(fill_in)\n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(convert_time)\n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(check)\n",
    "#flight_data['DEP_TIME'] = pd.to_datetime(flight_data['DEP_TIME'], format=)\n",
    "\n",
    "\n",
    "#------------------------------------Eliminating extra columns------------------------------#\n",
    "\n",
    "flight_data['OP_UNIQUE_CARRIER'].nunique()  # 17\n",
    "flight_data['OP_CARRIER_AIRLINE_ID'].nunique()  # 17\n",
    "flight_data['OP_CARRIER'].nunique() # 17\n",
    "# Remove both OP_CARRIER_AIRLINE_ID and OP_CARRIER\n",
    "del flight_data['OP_CARRIER_AIRLINE_ID']\n",
    "del flight_data['OP_CARRIER']\n",
    "\n",
    "flight_data['TAIL_NUM'].nunique() # 5445\n",
    "flight_data['ORIGIN_AIRPORT_ID'].nunique() # 346\n",
    "flight_data['ORIGIN_AIRPORT_SEQ_ID'].nunique() # 346\n",
    "# Remove ORIGIN_AIRPORT_SEQ_ID\n",
    "del flight_data['ORIGIN_AIRPORT_SEQ_ID']\n",
    "\n",
    "flight_data['DEST_AIRPORT_ID'].nunique() # 346\n",
    "flight_data['DEST_AIRPORT_SEQ_ID'].nunique() # 346\n",
    "# Remove DEST_AIRPORT_SEQ_ID\n",
    "del flight_data['DEST_AIRPORT_SEQ_ID']\n",
    "\n",
    "del flight_data['ORIGIN_AIRPORT_ID']\n",
    "del flight_data['DEST_AIRPORT_ID']\n",
    "\n",
    "flight_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis Preparation\n",
    "\n",
    "* Cancelled flights are removed from original dataset as they are not relevant to delay prediction\n",
    "* Dataset is split up into training data(60%), validation data(20%) and test data(20%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dictionary for all categorical data\n",
    "carrier_arr = flight_data['OP_UNIQUE_CARRIER'].unique()\n",
    "tail_arr = flight_data['TAIL_NUM'].unique()\n",
    "airport_arr = flight_data['ORIGIN'].append(flight_data['DEST']).unique()\n",
    "carrier_dict = dict([(x,i) for i,x in enumerate(carrier_arr)])\n",
    "tail_dict = dict([(x,i) for i,x in enumerate(tail_arr)])\n",
    "airport_dict = dict([(x,i) for i,x in enumerate(airport_arr)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all categorical data into number\n",
    "flight_data['OP_UNIQUE_CARRIER'] = flight_data['OP_UNIQUE_CARRIER'].map(carrier_dict)\n",
    "flight_data['TAIL_NUM'] = flight_data['TAIL_NUM'].map(tail_dict)\n",
    "flight_data['ORIGIN'] = flight_data['ORIGIN'].map(airport_dict)\n",
    "flight_data['DEST'] = flight_data['DEST'].map(airport_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelevent columns for analysis\n",
    "flight_data.drop(columns=['DEP_TIME','DEP_TIME_BLK','ARR_TIME','DIVERTED'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up data for analysis\n",
    "cancelled_flight = flight_data[flight_data['CANCELLED'] == 1.0].drop(columns=['CANCELLED'])\n",
    "normal_flight = flight_data[flight_data['CANCELLED'] == 0.0].drop(columns=['CANCELLED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up test and train data for normal flight\n",
    "train_data, test_data = train_test_split(normal_flight, train_size=0.8)\n",
    "train_data, val_data = train_test_split(train_data, train_size=0.75)\n",
    "train_dep = train_data['DEP_DEL15']\n",
    "train_arr = train_data['ARR_DEL15']\n",
    "val_dep = val_data['DEP_DEL15']\n",
    "val_arr = val_data['ARR_DEL15']\n",
    "test_dep = test_data['DEP_DEL15']\n",
    "test_arr = test_data['ARR_DEL15']\n",
    "train_data.drop(columns=['DEP_DEL15','ARR_DEL15'],inplace=True)\n",
    "test_data.drop(columns=['DEP_DEL15','ARR_DEL15'],inplace=True)\n",
    "val_data.drop(columns=['DEP_DEL15','ARR_DEL15'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_data = StandardScaler().fit_transform(train_data)\n",
    "pca = PCA().fit(std_data)\n",
    "pca_scores = pca.transform(std_data)\n",
    "#sns.scatterplot(x=pca_scores[:,0],y=pca_scores[:,1],hue=train_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_[0])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flight Delay Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of prediction against validation data given k-value\n",
    "def test_accuracy(k, mode='DEP'):\n",
    "    print('Running KNN with k =',k)\n",
    "    train_target = train_dep if mode == 'DEP' else train_arr\n",
    "    val_target = val_dep if mode == 'DEP' else val_arr\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance').fit(train_data, train_target)\n",
    "    return np.sum(knn.predict(val_data) == val_target) / len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[test_accuracy(k, mode='DEP') for k in range(1,10,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}