{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDS Mini Project\n",
    "\n",
    "\n",
    "**WARNING: Before making any git commit to this notebook please clear all output in this notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning the data\n",
    "\n",
    "### Invalid Columns: \n",
    "- delete unnamed column which was serving as index (index already exists - duplicated column)\n",
    "- delete last column (contains only NaN values) - 'Unnamed 21'\n",
    "\n",
    "### NaN values:\n",
    "- check number of NaN values/location of NaN values\n",
    "- leave NaN values that are required in order not to lose data (for example: a cancelled flight will always have NaN values for DEP_TIME, ARR_TIME, ARR_DEL15, DEP_DEL15 - as the flight did not happen)\n",
    "- delete NaN values that would incommodate analysis and plotting later on (for example, flight timings that are simply missing without the flight having been cancelled)\n",
    "\n",
    "### Times conversion (Note: 00:00 timings all represent cancelled flights)\n",
    "- observation --> no flight leaves at 00:00, all *00:00 date/time values belong to flights that have been cancelled*\n",
    "- converted DEP_TIME and ARR_TIME to 4-character string of the format: hhmm (error when attempting to convert to date/time) \n",
    "- added two extra columns: ARR_TIME_MINS and DEP_TIME_MINS representing the arrival and departure time in minutes for easier calculations\n",
    "\n",
    "### Irrelevant columns (to this project) to be removed/ duplicated data:\n",
    "- Remove both OP_CARRIER_AIRLINE_ID and OP_CARRIER\n",
    "- Remove ORIGIN_AIRPORT_SEQ_ID\n",
    "- Remove DEST_AIRPORT_SEQ_ID\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Importing sklearn functions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------- Load dataset ------------------------------------------#\n",
    "flight_data_path = os.path.join(os.getcwd(), 'datasets', 'flight_jan_2019.csv.gz')\n",
    "flight_data = pd.read_csv(flight_data_path, compression = 'gzip')\n",
    "\n",
    "# Delete 'Unnamed 1' and 'Unnamed 21'\n",
    "del flight_data['Unnamed: 0']\n",
    "del flight_data['Unnamed: 21']\n",
    "flight_data\n",
    "\n",
    "#---------------------------------------- Check for 'NaN' values ------------------------------#\n",
    "\n",
    "# for col in flight_data.columns: \n",
    "#    print(col, ' :',flight_data[col].isna().sum())\n",
    "    \n",
    "    # NA VALUES: TAIL_NUM  : 2543\n",
    "    #            DEP_TIME  : 16352\n",
    "    #            DEP_DEL15  : 16355\n",
    "    #            ARR_TIME  : 17061\n",
    "    #            ARR_DEL15  : 18022\n",
    "    #            Unnamed: 21  : 583985\n",
    "\n",
    "# Dealing with DEP_TIME and ARR_TIME Nan values\n",
    "flight_data[np.isnan(flight_data.DEP_TIME)] # Observation: cancelled flights have Nan values for DEP_TIME, ARR_TIME, DEP_DEL15,ARR_DEL15  \n",
    "# NaN values therefore make sense in this case, eliminating rows with NaN values with plotting can be done by filtering:\n",
    "#                       flight_data[~np.isnan(flight_data['DEP_TIME'])]['DEP_TIME'].isna().sum()    \n",
    "\n",
    "# Eliminate rows with NaN values in place for DEP/ARR_DELL15 AND ARR_TIME where the DEP_TIME is registered (timings simply missing)\n",
    "indices_to_eliminate = list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['DEP_DEL15'])].index.values) + list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['ARR_TIME'])].index.values) + list(flight_data[(~np.isnan(flight_data['DEP_TIME']))][np.isnan(flight_data['ARR_DEL15'])].index.values)\n",
    "flight_data = flight_data.drop(indices_to_eliminate)\n",
    "\n",
    "#--------------------------------------Modifying data types----------------------------------#\n",
    "flight_data.dtypes\n",
    "# CANCELLED/DIVERTED to integer value\n",
    "flight_data['CANCELLED'] = flight_data['CANCELLED'].astype(int)\n",
    "flight_data['DIVERTED'] = flight_data['DIVERTED'].astype(int)\n",
    "flight_data.dtypes\n",
    "flight_data\n",
    "# Modifying timings date/time format\n",
    "#flight_data['DEP_TIME'] = pd.to_datetime(flight_data['DEP_TIME'], format='%H%M').dt.time\n",
    "\n",
    "# OBSERVATION: flights with value 0.0 - keeping in mind that timings are currently floats - are all NaN values - so no flight leaves at 00:00 (those are simply cancelled values)\n",
    "len(flight_data[(flight_data['DEP_TIME'] == 0.0)][flight_data['CANCELLED'] == 1]['DEP_TIME']) - flight_data[flight_data['DEP_TIME'] == 0.0]['DEP_TIME'].isna().sum()\n",
    "len(flight_data[(flight_data['DEP_TIME'] == 0.0)][flight_data['CANCELLED'] == 1]['DEP_TIME']) - flight_data[flight_data['DEP_TIME'] == 0.0]['DEP_TIME'].isna().sum()\n",
    "\n",
    "# Convert DEP_TIME and ARR_TIME to int and add new columns: DEP_TIME_MINS and ARR_TIME_MINS for easy calculations\n",
    "def convert_minutes(x):\n",
    "    minutes = int(x[2])*10 + int(x[3])\n",
    "    hr_minutes = (int(x[0])*10 + int(x[1]))*60\n",
    "    return minutes+hr_minutes\n",
    "\n",
    "def fill_in(x):\n",
    "    if (len(x) == 4):\n",
    "        return x\n",
    "    if (len(x) == 3):\n",
    "        return '0' + x\n",
    "    if (len(x) == 2):\n",
    "        return '00' + x\n",
    "    if (len(x) == 1):\n",
    "        return '000' + x\n",
    "    if (len(x) == 0):\n",
    "        return '000' + x\n",
    "    return '0000'\n",
    "    \n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].fillna(0)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].astype(int)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].astype(str)\n",
    "flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(fill_in)\n",
    "flight_data['DEP_TIME_MINS'] = flight_data['DEP_TIME'].apply(convert_minutes)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].fillna(0)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].astype(int)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].astype(str)\n",
    "flight_data['ARR_TIME'] = flight_data['ARR_TIME'].apply(fill_in)\n",
    "flight_data['ARR_TIME_MINS'] = flight_data['ARR_TIME'].apply(convert_minutes)\n",
    "\n",
    "#-------------------------------ATTEMPT AT CONVERTING TO DATE/TIME-----------------#\n",
    "def fill_in(x):\n",
    "    if (len(x) == 4):\n",
    "        return x\n",
    "    if (len(x) == 3):\n",
    "        return '0' + x\n",
    "    if (len(x) == 2):\n",
    "        return '00' + x\n",
    "    if (len(x) == 1):\n",
    "        return '000' + x\n",
    "    if (len(x) == 0):\n",
    "        return '000' + x\n",
    "    return '0000'\n",
    "    \n",
    "#def convert_time(x):\n",
    "#    return datetime.datetime.strptime(x,'%H%M' )\n",
    "    \n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(fill_in)\n",
    "#flight_data['ARR_TIME'] = flight_data['ARR_TIME'].apply(fill_in)\n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(convert_time)\n",
    "#flight_data['DEP_TIME'] = flight_data['DEP_TIME'].apply(check)\n",
    "#flight_data['DEP_TIME'] = pd.to_datetime(flight_data['DEP_TIME'], format=)\n",
    "\n",
    "\n",
    "#------------------------------------Eliminating extra columns------------------------------#\n",
    "\n",
    "flight_data['OP_UNIQUE_CARRIER'].nunique()  # 17\n",
    "flight_data['OP_CARRIER_AIRLINE_ID'].nunique()  # 17\n",
    "flight_data['OP_CARRIER'].nunique() # 17\n",
    "# Remove both OP_CARRIER_AIRLINE_ID and OP_CARRIER\n",
    "del flight_data['OP_CARRIER_AIRLINE_ID']\n",
    "del flight_data['OP_CARRIER']\n",
    "\n",
    "flight_data['TAIL_NUM'].nunique() # 5445\n",
    "flight_data['ORIGIN_AIRPORT_ID'].nunique() # 346\n",
    "flight_data['ORIGIN_AIRPORT_SEQ_ID'].nunique() # 346\n",
    "# Remove ORIGIN_AIRPORT_SEQ_ID\n",
    "del flight_data['ORIGIN_AIRPORT_SEQ_ID']\n",
    "\n",
    "flight_data['DEST_AIRPORT_ID'].nunique() # 346\n",
    "flight_data['DEST_AIRPORT_SEQ_ID'].nunique() # 346\n",
    "# Remove DEST_AIRPORT_SEQ_ID\n",
    "del flight_data['DEST_AIRPORT_SEQ_ID']\n",
    "\n",
    "del flight_data['ORIGIN_AIRPORT_ID']\n",
    "del flight_data['DEST_AIRPORT_ID']\n",
    "\n",
    "flight_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis Preparation / Pre-processing\n",
    "\n",
    "### Data selection:\n",
    "\n",
    "* As we only need reliable data, which the flight were not cancelled, the normal_flight is filtered from the original dataset\n",
    "* By combining or processing some of the columns, the data would be more concise and brief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_flight = flight_data[flight_data['CANCELLED'] == 0.0].drop(columns=['CANCELLED','DEP_TIME','DEP_TIME_BLK','ARR_TIME','DIVERTED','TAIL_NUM'])\n",
    "normal_flight['FLIGHT_NUM'] = normal_flight.apply(lambda x : x['OP_UNIQUE_CARRIER'] + str(x['OP_CARRIER_FL_NUM']), axis=1)\n",
    "normal_flight['TRAVEL_TIME'] = normal_flight.apply(lambda x : x['ARR_TIME_MINS'] - x['DEP_TIME_MINS'], axis=1)\n",
    "normal_flight.drop(columns=['OP_CARRIER_FL_NUM','ARR_TIME_MINS'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_flight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transfer\n",
    "\n",
    "* Transfering the categorical data to relative delay rate(Better observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by each column and calculate delay rate (DEP_DR and ARR_DR) of each attribute\n",
    "cols = ['DAY_OF_MONTH','DAY_OF_WEEK','OP_UNIQUE_CARRIER','FLIGHT_NUM','ORIGIN','DEST']\n",
    "for col in cols:\n",
    "    dep_name, arr_name = 'DEP_DR_'+col, 'ARR_DR_'+col\n",
    "    stat = normal_flight[[col, 'DEP_DEL15', 'ARR_DEL15']].groupby(col).transform('mean')\n",
    "    normal_flight[dep_name] = stat['DEP_DEL15']\n",
    "    normal_flight[arr_name] = stat['ARR_DEL15']\n",
    "normal_flight.drop(columns=cols,inplace=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normal_flight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_ontime_cnt, dep_delay_cnt = np.sum(normal_flight['DEP_DEL15'] == 0.0), np.sum(normal_flight['DEP_DEL15'] == 1.0)\n",
    "arr_ontime_cnt, arr_delay_cnt = np.sum(normal_flight['ARR_DEL15'] == 0.0), np.sum(normal_flight['ARR_DEL15'] == 1.0)\n",
    "# plt.title('Delay Statistics')\n",
    "stat_df = pd.DataFrame({'Type': ['Departure','Departure','Arrival','Arrival'], 'Status': ['Ontime','Delayed','Ontime','Delayed'], 'Flight Count': [dep_ontime_cnt, dep_delay_cnt, arr_ontime_cnt, arr_delay_cnt]})\n",
    "plt.ylim((0,500000))\n",
    "plt.title('Delay Statistics Jan 2019')\n",
    "sns.barplot(data=stat_df, x='Type', y='Flight Count', hue='Status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PCA Analysis\n",
    "\n",
    "### Training preparation\n",
    "\n",
    "* Cancelled flights are removed from original dataset as they are not relevant to delay prediction\n",
    "* Dataset is split up into training data(60%), validation data(20%) and test data(20%)\n",
    "\n",
    "\n",
    "### Implement of PCA\n",
    "\n",
    "* Choose n = 6, PCA would help us to do Dimension reduction\n",
    "* (Reduce the computational overhead of the algorithm and Reserve most of the data: 80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up test and train data for normal flight\n",
    "all_dep = normal_flight['DEP_DEL15']\n",
    "all_arr = normal_flight['ARR_DEL15']\n",
    "all_data = normal_flight.drop(columns=['DEP_DEL15','ARR_DEL15'])\n",
    "all_data = StandardScaler().fit_transform(all_data)\n",
    "pca = PCA(n_components=6).fit(all_data)\n",
    "all_data = pca.transform(all_data)\n",
    "train_data, test_data = train_test_split(all_data, train_size=0.8, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, train_size=0.75, random_state=42)\n",
    "train_dep, test_dep = train_test_split(all_dep, train_size=0.8, random_state=42)\n",
    "train_dep, val_dep = train_test_split(train_dep, train_size=0.75, random_state=42)\n",
    "train_arr, test_arr = train_test_split(all_arr, train_size=0.8, random_state=42)\n",
    "train_arr, val_arr = train_test_split(train_arr, train_size=0.75, random_state=42)\n",
    "print('Data reserved by PCA (in percentage):', np.sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Ontime Departure Flights')\n",
    "sns.scatterplot(x=train_data[train_dep == 0.0][:,0], y=train_data[train_dep == 0.0][:,1], color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Delayed Departure Flights')\n",
    "sns.scatterplot(x=train_data[train_dep == 1.0][:,0], y=train_data[train_dep == 1.0][:,1], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Flight Delay Prediction\n",
    "\n",
    "### Implement of KNN:\n",
    "\n",
    "* View the different results with different k-value, choose the best one(observation) among all of them.\n",
    "* We would use False Positive and False Negative to see the correctness of result\n",
    "\n",
    "* False Positive : Prediction is True, but the truth is False\n",
    "* False Negative : Prediction is False, but the truth is True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of prediction against validation data given k-value\n",
    "def test_accuracy(k, mode='DEP'):\n",
    "    print('Running KNN with k =',k)\n",
    "    train_target = train_dep if mode == 'DEP' else train_arr\n",
    "    val_target = val_dep if mode == 'DEP' else val_arr\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', n_jobs=-1).fit(train_data, train_target)\n",
    "    prediction = knn.predict(val_data)\n",
    "    # false positive, prediction > target\n",
    "    fp = np.sum(prediction > val_target) / len(val_data)\n",
    "    # false negative, prediction < target\n",
    "    fn = np.sum(prediction < val_target) / len(val_data)\n",
    "    return [k,fp,fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result = np.array([test_accuracy(k, mode='DEP') for k in range(1,50,4)])\n",
    "plt.plot(run_result[:,0], run_result[:,1], 'r') # False positive\n",
    "plt.plot(run_result[:,0], run_result[:,2], 'b') # False negative\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_knn = KNeighborsClassifier(n_neighbors=9, weights='distance', n_jobs=-1).fit(train_data, train_dep)\n",
    "dep_prediction = dep_knn.predict(test_data)\n",
    "dep_fp = np.sum(dep_prediction > test_dep) / len(test_data)\n",
    "dep_fn = np.sum(dep_prediction < test_dep) / len(test_data)\n",
    "dep_fp, dep_fn # (false positive rate, false negative rate) for departure delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_result = np.array([test_accuracy(k, mode='ARR') for k in range(1,50,4)])\n",
    "plt.plot(run_result[:,0], run_result[:,1], 'r') # False positive\n",
    "plt.plot(run_result[:,0], run_result[:,2], 'b') # False negative\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_knn = KNeighborsClassifier(n_neighbors=9, weights='distance', n_jobs=-1).fit(train_data, train_arr)\n",
    "arr_prediction = arr_knn.predict(test_data)\n",
    "arr_fp = np.sum(arr_prediction > test_arr) / len(test_data)\n",
    "arr_fn = np.sum(arr_prediction < test_arr) / len(test_data)\n",
    "arr_fp, arr_fn # (false positive rate, false negative rate) for arrival delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis\n",
    "\n",
    "### Dataset URL:\n",
    "* https://www.kaggle.com/divyansh22/flight-delay-prediction\n",
    "* The data of detail of flight is collected, we could use the details to predict the flight will delay or not.\n",
    "\n",
    "\n",
    "### QUESTIONS:\n",
    "\n",
    "* The delay of the flight is annoying, it would usually cause a series of time conflict. Therefore, we're wondering that what if we could predict the delay of the flight, then we could preplan the schedule and use the time more properly\n",
    "\n",
    "\n",
    "### TOOL:\n",
    "\n",
    "* it is a prediction problem, we are trying to predict whether or not the flight will delay.\n",
    "* we use the the distance between the origin and destination, total travel minutes, the time block and etc. to predict the probability of delay.\n",
    "\n",
    "* And the reason why we choose them is because they are relative to the delay(e.g. Knowing the distance from one city to another and travel time could be seen as reference to predict the flight will delay or not) \n",
    "* We used standardised data, which could be more precise and accurate.\n",
    "* With what we said in (4,Implement of KNN),  false positive and false negative are used to see the result.\n",
    "\n",
    "\n",
    "### ANALYSIS & FINDINGS:\n",
    "\n",
    "* Even we have a quite good prediction through the regression model, but it still have some problem. From the original data, we know that the sample number of flight which not dalayed is totally greater than that of flight which delayed, it is also a reason why the probability of the false positive is smaller than that of false negative.\n",
    "* graph can be seen in the bottom of (4. Flight Delay Prediction)\n",
    "\n",
    "### FUTURE DIRECTIONS:\n",
    "\n",
    "* There still a lot of event which has not been considered might happened before departure of the flight(the number and weight of luggage, missing passengers and etc.), \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}